{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4ec3e-ca37-4148-a61e-164a8c14855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979b186-18c9-4eb6-a1a7-4792db630d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_users.csv')\n",
    "df_test = pd.read_csv('test_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867da12e-68a2-4cce-9e8c-eefa86dd7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d583d1-f431-4c8d-81b5-f470db1dc381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7c132-c675-48eb-8d93-d5e7a4abc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"] = df_train[\"label\"].str.replace(\"_\", \"\", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb2b37-a959-48f9-992e-15f9afa4daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb82c0e-29d8-4c62-84e1-fcde52323b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_train.dtypes)\n",
    "print(\"\\nUnique labels:\", df_train[\"label\"].unique())\n",
    "print(\"\\nLabel counts:\\n\", df_train[\"label\"].value_counts())\n",
    "print(\"\\nLabel proportions:\\n\", df_train[\"label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a7a43-f5c1-478d-a631-d792ef2898bd",
   "metadata": {},
   "source": [
    "# box plot for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c90ae-0757-42a5-9e39-83a9bb20d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"subscriber\"] = df_train[\"subscriber\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c12043-8a9b-46ef-a4cf-771815fb3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [c for c in df_train.columns if c not in [\"user_id\", \"label\", \"browser_version\", \"region_code\"]]\n",
    "\n",
    "for c in feat_cols:\n",
    "    plt.figure()\n",
    "    data = [df_train[df_train[\"label\"]==lab][c].dropna() for lab in sorted(df_train[\"label\"].unique())]\n",
    "    plt.boxplot(data, labels=sorted(df_train[\"label\"].unique()))\n",
    "    plt.title(f\"Boxplot: {c} by label\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2caf6a-c82f-4e25-aa9c-7530c53065a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"browser_version\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619a30a-0ab9-47a1-9f96-e408cdb69e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"user_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b22d0-56c5-4e4f-906c-7aa5287bd19b",
   "metadata": {},
   "source": [
    "# applying different models with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01af7d9b-eb3e-4c31-b532-f98a4dc91b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [c for c in df_train.columns if c not in [\"user_id\", \"label\", \"browser_version\", \"region_code\"]]\n",
    "target = \"label\"\n",
    "\n",
    "X = df_train[feat_cols]\n",
    "y = df_train[\"label\"].astype(str)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "prep_tree = ColumnTransformer(\n",
    "    [(\"num\", SimpleImputer(strategy=\"median\"), feat_cols)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "prep_scaled = ColumnTransformer(\n",
    "    [(\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), feat_cols)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"DecisionTree\": Pipeline([\n",
    "        (\"prep\", prep_tree),\n",
    "        (\"clf\", DecisionTreeClassifier(random_state=42, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"prep\", prep_tree),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    \"HistGradientBoosting\": Pipeline([\n",
    "        (\"prep\", prep_tree),\n",
    "        (\"clf\", HistGradientBoostingClassifier(\n",
    "            max_depth=6, learning_rate=0.05, max_iter=800, random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"prep\", prep_scaled),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=5000,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    \"SVM_RBF\": Pipeline([\n",
    "        (\"prep\", prep_scaled),\n",
    "        (\"clf\", SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=10,\n",
    "            gamma=\"scale\",\n",
    "            class_weight=\"balanced\"\n",
    "        ))\n",
    "    ]),\n",
    "    \"MLP\": Pipeline([\n",
    "        (\"prep\", prep_scaled),\n",
    "        (\"clf\", MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 64),\n",
    "            alpha=1e-4,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"macro_f1\": \"f1_macro\"\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    out = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    acc_mean, acc_std = out[\"test_acc\"].mean(), out[\"test_acc\"].std()\n",
    "    f1_mean, f1_std = out[\"test_macro_f1\"].mean(), out[\"test_macro_f1\"].std()\n",
    "\n",
    "    rows.append([name, acc_mean, acc_std, f1_mean, f1_std])\n",
    "\n",
    "results = pd.DataFrame(rows, columns=[\"model\", \"acc_mean\", \"acc_std\", \"macroF1_mean\", \"macroF1_std\"])\n",
    "results = results.sort_values(\"acc_mean\", ascending=False)\n",
    "\n",
    "print(results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dae628-0f2e-42f4-96b5-02cde6950c3a",
   "metadata": {},
   "source": [
    "# checking with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10a563-02df-445c-b627-814b84cbecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feat_cols = [c for c in df_train.columns if c not in [\"user_id\", \"label\", \"browser_version\", \"region_code\"]]\n",
    "target = \"label\"\n",
    "\n",
    "X = df_train[feat_cols]\n",
    "y = df_train[target].astype(str)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# shared preprocessing: impute -> scale -> PCA(5)\n",
    "prep_pca5 = ColumnTransformer(\n",
    "    [(\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=5, random_state=42)),\n",
    "    ]), feat_cols)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "models_pca = {\n",
    "    \"DecisionTree_PCA5\": Pipeline([\n",
    "        (\"prep\", prep_pca5),\n",
    "        (\"clf\", DecisionTreeClassifier(random_state=42, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "    \"RandomForest_PCA5\": Pipeline([\n",
    "        (\"prep\", prep_pca5),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    \"HistGradientBoosting_PCA5\": Pipeline([\n",
    "        (\"prep\", prep_pca5),\n",
    "        (\"clf\", HistGradientBoostingClassifier(\n",
    "            max_depth=6, learning_rate=0.05, max_iter=800, random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "    \"LogisticRegression_PCA5\": Pipeline([\n",
    "        (\"prep\", prep_pca5),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=5000,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    \"SVM_RBF_PCA5\": Pipeline([\n",
    "        (\"prep\", prep_pca5),\n",
    "        (\"clf\", SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=10,\n",
    "            gamma=\"scale\",\n",
    "            class_weight=\"balanced\"\n",
    "        ))\n",
    "    ]),\n",
    "    \"MLP_PCA5\": Pipeline([\n",
    "        (\"prep\", prep_pca5),\n",
    "        (\"clf\", MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 64),\n",
    "            alpha=1e-4,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "scoring = {\"acc\": \"accuracy\", \"macro_f1\": \"f1_macro\"}\n",
    "\n",
    "rows = []\n",
    "for name, model in models_pca.items():\n",
    "    out = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    rows.append([\n",
    "        name,\n",
    "        out[\"test_acc\"].mean(), out[\"test_acc\"].std(),\n",
    "        out[\"test_macro_f1\"].mean(), out[\"test_macro_f1\"].std()\n",
    "    ])\n",
    "\n",
    "results = pd.DataFrame(rows, columns=[\"model\", \"acc_mean\", \"acc_std\", \"macroF1_mean\", \"macroF1_std\"])\n",
    "results = results.sort_values(\"acc_mean\", ascending=False)\n",
    "print(results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b872f37-243d-4b35-963c-da13e8ce5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much variance is explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e4157-a0d8-4138-bce3-94873c0cc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"prep\", prep_pca5),\n",
    "])\n",
    "Z = pipe.fit_transform(X, y)  # not needed for training; just for inspection\n",
    "\n",
    "# Get explained variance ratio from the fitted PCA inside the ColumnTransformer:\n",
    "pca = pipe.named_steps[\"prep\"].named_transformers_[\"num\"].named_steps[\"pca\"]\n",
    "print(\"Explained variance (sum, 5 PCs):\", pca.explained_variance_ratio_.sum())\n",
    "print(\"Per-PC:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a42fd-a10d-46cb-a80a-c2d50f3a10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5223c2-9a4e-497e-885a-a84ee14aa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pca.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2199a-12d1-499b-a8c1-9392ea88182b",
   "metadata": {},
   "source": [
    "# Taking the best model and train on the whole set and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0c5a2-2362-434b-a53e-d404a0a8dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = df_train[feat_cols]\n",
    "y_train = df_train[\"label\"].astype(str)\n",
    "\n",
    "X_test  = df_test[feat_cols]\n",
    "\n",
    "best_model = models['RandomForest']   \n",
    "\n",
    "# full train\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test\n",
    "test_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5edfa-7e10-4814-87c0-8bb375f04d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = test_pred\n",
    "df_test.to_csv('test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93971e-ffd3-4e7f-a081-7ffbe8006edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rlcmab_sampler import sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07922be-e2bc-46e0-9d3c-505f190bd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_number = 4\n",
    "reward_sampler = sampler(roll_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daca4f0-34f7-4b87-a0cc-477db2a30d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d0589-05db-45a8-afe7-18790c55426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = ['user1', 'user2', 'user3']\n",
    "categories = [\"ENTERTAINMENT\", \"EDUCATION\", \"TECH\", \"CRIME\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430e387-4967-467d-aff3-9a9854a01872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arm_index(context_id, category_id):\n",
    "    # context_id = 0,1,2\n",
    "    # category_id = 0,1,2,3\n",
    "    return context_id * 4 + category_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edde6c-e593-4b18-a944-1961fa2b3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_category(Q):\n",
    "    # greedy (choose argmax Q)\n",
    "    return int(np.argmax(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca4214-811f-4f17-ab70-57df425f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.01, 0.05, 0.1]\n",
    "results_egreedy = {eps: {} for eps in epsilons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543eba3f-d8d3-4fc0-9f56-b1938a065d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons:\n",
    "    for context_idx, context_name in enumerate(contexts):\n",
    "        Q = np.zeros(len(categories), dtype = float) # Q-value for categories of news\n",
    "        N = np.zeros(len(categories), dtype = int) # count for each categpry, i.e., how many times reward for each category is called/estimated.\n",
    "        rewards = np.zeros(T, dtype=float) # per step reward\n",
    "\n",
    "        for t in range(T):\n",
    "            if np.random.rand() < eps:\n",
    "                category_idx = np.random.randint(len(categories)) # explore from categories\n",
    "            else:\n",
    "                max_q = np.max(Q) # exploit by taking max \n",
    "                # but there can be multiple max_q. if we always pics the first max then we will be bias toward one category.\n",
    "                candidates = [i for i, x in enumerate(Q) if x == max_q]\n",
    "                category_idx = np.random.choice(candidates)\n",
    "            \n",
    "            # sample reward for category/arm\n",
    "            j = arm_index(context_idx, category_idx)\n",
    "            r = reward_sampler.sample(j)\n",
    "\n",
    "            N[category_idx] += 1\n",
    "            Q[category_idx] += (r - Q[category_idx]) / N[category_idx]\n",
    "            rewards[t] = r\n",
    "        \n",
    "        avg_rewards = np.cumsum(rewards) / (np.arange(T) + 1)\n",
    "\n",
    "        results_egreedy[eps][context_name] = {\n",
    "            \"Q\": Q.copy(),\n",
    "            \"N\": N.copy(),\n",
    "            \"rewards\": rewards,\n",
    "            \"avg_rewards\": avg_rewards\n",
    "        }\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed45256-50a7-4d1c-98e8-29568fb68db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons:\n",
    "    print(f\"\\nEpsilon={eps}\")\n",
    "    for context_name in contexts:\n",
    "        Q = results_egreedy[eps][context_name][\"Q\"]\n",
    "        print(f\"  {context_name} Q-values: \" + \", \".join([f\"{cat}:{q:.4f}\" for cat,q in zip(categories, Q)]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0abf7-a3d2-4b93-a31c-824155db8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_name in contexts:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for eps in epsilons:\n",
    "        avg = results_egreedy[eps][context_name]['avg_rewards']\n",
    "        plt.plot(avg, label=f\"epsilon={eps}\")\n",
    "    plt.title(f\"Avg Reward vs Time | {context_name} | Epsilon-Greedy\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(\"Average reward\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a60d48-3ba8-47a0-9242-c919eacd63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.5, 1.0, 2.0]\n",
    "results_ucb = {C:{} for C in Cs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920e6d4-1cd6-4ea6-a1a6-313e4e01873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in Cs:\n",
    "    for context_idx, context_name in enumerate(contexts):\n",
    "        Q = np.zeros(len(categories), dtype = float)\n",
    "        N = np.zeros(len(categories), dtype = int)\n",
    "        rewards = np.zeros(T, dtype = float)\n",
    "\n",
    "        for t in range(T):\n",
    "            if (N == 0).any():\n",
    "                category_idx = np.where(N==0)[0][0]\n",
    "            else:\n",
    "                ucb = Q + C * np.sqrt(np.log(t+1)/N)\n",
    "                category_idx = int(np.argmax(ucb))\n",
    "                \n",
    "            j = arm_index(context_idx, category_idx)\n",
    "            r = reward_sampler.sample(j)\n",
    "\n",
    "            N[category_idx] += 1\n",
    "            Q[category_idx] += (r - Q[category_idx])/N[category_idx]\n",
    "            rewards[t] = r\n",
    "            \n",
    "        avg_rewards = np.cumsum(rewards)/(np.arange(T) + 1)\n",
    "\n",
    "        results_ucb[C][context_name] = {\n",
    "            'Q' : Q.copy(),\n",
    "            'N' : N.copy(),\n",
    "            'rewards' : rewards,\n",
    "            \"avg_rewards\" : avg_rewards\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fae7ad-e3a8-4bd6-a069-fe4f749042a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in Cs:\n",
    "    print(f\"C = {C}\")\n",
    "    for context_name in contexts:\n",
    "        Q = results_ucb[C][context_name]['Q']\n",
    "        print(f\"  {context_name} Q-values: \" + \", \".join([f\"{cat}:{q:.4f}\" for cat,q in zip(categories, Q)]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff202d-6a57-4ab5-9065-c68012776cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_name in contexts:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for C in Cs:\n",
    "        avg = results_ucb[C][context_name]['avg_rewards']\n",
    "        plt.plot(avg, label = f\"C={C}\")\n",
    "    plt.title(f\"Avg Reward vs Time | {context_name} | UCB\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(\"Average reward\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ecbf8-3729-482a-b223-6a006b4daecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1.0\n",
    "results_softmax = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3935f0-6f88-4d72-8929-2d0d31d6f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_idx, context_name in enumerate(contexts):\n",
    "    Q = np.zeros(len(categories), dtype = float)\n",
    "    N = np.zeros(len(categories), dtype = int)\n",
    "    rewards = np.zeros(T, dtype = float)\n",
    "\n",
    "    for t in range(T):\n",
    "        z = Q/tau\n",
    "        z = z - np.max(z)\n",
    "        probs = np.exp(z)\n",
    "        probs = probs / probs.sum()\n",
    "\n",
    "        category_idx = np.random.choice(len(categories), p = probs)\n",
    "        j = arm_index(context_idx, category_idx)\n",
    "        r = reward_sampler.sample(j)\n",
    "\n",
    "        N[category_idx] += 1\n",
    "        Q[category_idx] += (r - Q[category_idx]) / N[category_idx]\n",
    "        rewards[t] = r\n",
    "    avg_rewards = np.cumsum(rewards) / (np.arange(T) + 1)\n",
    "\n",
    "    results_softmax[context_name] = {\n",
    "        \"Q\": Q.copy(),\n",
    "        \"N\": N.copy(),\n",
    "        \"rewards\": rewards,\n",
    "        \"avg_rewards\": avg_rewards\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa11c70-a146-45c3-b5c7-d5cb5db884f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_name in contexts:\n",
    "    Q = results_softmax[context_name][\"Q\"]\n",
    "    print(f\"{context_name} Q-values: \" + \", \".join([f\"{cat}:{q:.4f}\" for cat,q in zip(categories, Q)]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02157722-3436-4abc-8cff-8341deb91256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_name in contexts:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    avg = results_softmax[context_name][\"avg_rewards\"]\n",
    "    plt.plot(avg, label=f\"tau={tau}\")\n",
    "    plt.title(f\"Avg Reward vs Time | {context_name} | Softmax\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(\"Average reward\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644bb20-45d5-4e45-9449-c057bb47e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_category(Q):\n",
    "    # greedy (choose argmax Q)\n",
    "    return int(np.argmax(Q))\n",
    "    \n",
    "def recommend_for_policy(users, policy_name, policy_state, articles):\n",
    "    outputs = []\n",
    "    user_context = users['label']\n",
    "    for i, context in enumerate(user_context):\n",
    "        context = str(context)\n",
    "        Q = policy_state[context][\"Q\"]\n",
    "\n",
    "        # choose category (greedy)\n",
    "        category_idx = select_best_category(Q)\n",
    "        cat = categories[category_idx]\n",
    "\n",
    "        temp = articles.loc[articles['category']==cat]\n",
    "        if len(temp) == 0:\n",
    "            article = None\n",
    "        else:\n",
    "            random_row = temp.sample()\n",
    "            \n",
    "            \n",
    "        outputs.append({\n",
    "            \"user_id\": users.iloc[i][\"user_id\"],\n",
    "            \"predicted_context\": context,\n",
    "            \"recommended_category\": cat,\n",
    "            \"link\": random_row['link'].values[0],\n",
    "            \"short_description\": random_row['short_description'].values[0],\n",
    "            \"headline\": random_row['headline'].values[0],\n",
    "        })\n",
    "    return outputs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07922d6-36e6-4ac3-a8c6-ec41c84fe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('news_articles.csv')\n",
    "category_col = \"category\"\n",
    "articles = articles[articles[category_col].isin(categories)].copy()\n",
    "articles = articles.reset_index(drop=True)\n",
    "articles.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9c83c-bc05-4dcd-9d89-fb7926efe86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_pred.csv')\n",
    "user_context = df_test[['user_id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb8537-1564-4788-b599-d22454de54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the hyperparams to use for epsilon/UCB\n",
    "best_eps = 0.05\n",
    "best_C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05881be-d8a3-499c-9003-2624cececa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_policy = {context: results_egreedy[best_eps][context] for context in contexts}\n",
    "ucb_policy = {context: results_ucb[best_C][context] for context in contexts}\n",
    "softmax_policy = results_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8039e25-d6b2-4e71-85bf-a9495feec17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_recos = recommend_for_policy(user_context, \"epsilon\", eps_policy, articles)\n",
    "ucb_recos = recommend_for_policy(user_context, \"ucb\", ucb_policy, articles)\n",
    "softmax_recos = recommend_for_policy(user_context, \"softmax\", softmax_policy, articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f553ed-f9a5-4325-8ed2-c3c01c9ea0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_recos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739bbb1-3f01-40ef-97b6-4ea6b24bd6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
